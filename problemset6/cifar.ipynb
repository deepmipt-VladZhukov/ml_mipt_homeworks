{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR Conv Net\n",
    "\n",
    "И так, в этом ноутбуке Вы сделаете превую в своей жизни сверточную сеть! На сложном датасете. Cкачайте его кстати, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# !mkdir cifar10\n",
    "# !curl -o cifar-10-python.tar.gz https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
    "# !tar -xvzf cifar-10-python.tar.gz -C cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: GeForce GTX 980 (CNMeM is disabled, cuDNN 5105)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage.interpolation import rotate\n",
    "from lasagne.layers import batch_norm\n",
    "import cv2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from cifar import load_CIFAR10\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) \n",
    "\n",
    "cifar10_dir = './cifar10/cifar-10-batches-py'\n",
    "X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
    "X_train = X_train.astype(np.float32)\n",
    "y_train = y_train.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "# num_classes = len(classes)\n",
    "# samples_per_class = 7\n",
    "# for y, cls in enumerate(classes):\n",
    "#     idxs = np.flatnonzero(y_train == y)\n",
    "#     idxs = np.random.choice(idxs, samples_per_class, replace=False)\n",
    "#     for i, idx in enumerate(idxs):\n",
    "#         plt_idx = i * num_classes + y + 1\n",
    "#         plt.subplot(samples_per_class, num_classes, plt_idx)\n",
    "#         plt.imshow(X_train[idx].astype('uint8').transpose(1, 2, 0))\n",
    "#         plt.axis('off')\n",
    "#         if i == 0:\n",
    "#             plt.title(cls)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "augmentation = []\n",
    "augmentation_y = []\n",
    "len1 = len(X_train)\n",
    "angles = [0, 90, 180, 270]\n",
    "for img, lbl in zip(X_train, y_train):\n",
    "    img0 = img.astype('uint8').transpose(1, 2, 0)\n",
    "    augmentation.append(img0.astype('uint8').transpose(2, 0, 1))\n",
    "    augmentation.append(cv2.flip(img0, 1).astype('uint8').transpose(2, 0, 1))\n",
    "    augmentation_y.append(lbl)\n",
    "    augmentation_y.append(lbl)\n",
    "    \n",
    "#     rows,cols = (32, 32)\n",
    "#     for a in [90, -90]:\n",
    "#         M = cv2.getRotationMatrix2D((cols/2,rows/2),a,1)\n",
    "#         dst = cv2.warpAffine(img0,M,(cols,rows))\n",
    "#         dst = dst.astype('uint8').astype('uint8').transpose(2, 0, 1)\n",
    "#         augmentation.append(dst)\n",
    "#         augmentation_y.append(lbl)\n",
    "X_train = np.array(augmentation)\n",
    "y_train = np.array(augmentation_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">First of all -- Checking Questions</h1> \n",
    "\n",
    "**Вопрос 1**: Чем отличаются современные сверточные сети от сетей 5 летней давности?\n",
    "\n",
    "<Ответ>\n",
    "\n",
    "**Вопрос 2**: Какие неприятности могут возникнуть во время обучения современных нейросетей?\n",
    "\n",
    "<Ответ>\n",
    "\n",
    "**Вопрос 3**: У вас есть очень маленький датасет из 100 картинок, но вы очень хотите использовать нейросеть, какие неприятности вас ждут и как их решить?\n",
    "\n",
    "<Ответ>\n",
    "\n",
    "**Вопрос 4**: У вас есть очень маленький датасет из 100 картинок, классификация, но вы очень хотите использовать нейросеть, какие неприятности вас ждут и как их решить? что делать если первый вариант  решения не заработает?\n",
    "\n",
    "<Ответ>\n",
    "\n",
    "**Вопрос 5**: Как сделать стайл трансфер для музыки? oO\n",
    "\n",
    "<Ответ>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import lasagne\n",
    "from theano import tensor as T\n",
    "from lasagne.nonlinearities import *\n",
    "from lasagne.layers import MaxPool2DLayer, InputLayer, Conv2DLayer as ConvLayer\n",
    "from lasagne.layers import NonlinearityLayer\n",
    "from lasagne.layers import ElemwiseSumLayer\n",
    "from lasagne.layers import ExpressionLayer\n",
    "from lasagne.layers import PadLayer\n",
    "from lasagne.layers import GlobalPoolLayer\n",
    "from lasagne.layers import DenseLayer\n",
    "\n",
    "input_X = T.tensor4(\"X\", dtype='float32')\n",
    "target_y = T.vector(\"target Y integer\",dtype='int32')  ##carefull! use int32 for gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Соберите нейронку: \n",
    "- Many times x (Conv+Pool)\n",
    "- Many small convolutions like 3x3\n",
    "- Batch Norm \n",
    "- Residual Connection\n",
    "- Data Augmentation \n",
    "- Learning rate Schedule \n",
    "- ...\n",
    "\n",
    "### Для вдохновения \n",
    "- http://torch.ch/blog/2015/07/30/cifar.html\n",
    "- http://www.robots.ox.ac.uk/~vgg/research/very_deep/\n",
    "- https://www.cs.unc.edu/~wliu/papers/GoogLeNet.pdf\n",
    "- https://github.com/szagoruyko/wide-residual-networks \n",
    "\n",
    "### Самое интересное\n",
    "- Для сдачи задания нужно набрать на точность тесте > **92.5**% (это займет много времени, торопитесь :) )\n",
    "- Для получения бонусных баллов > **95.0**%\n",
    "- Будет очень хорошо если вы придумаете свою архитектуру или сможете обучить что-то из вышеперечисленного :)\n",
    "- А для обучения всего этого добра вам будет куда удобнее использовать GPU на Amazon \n",
    "    - Инструкция https://github.com/persiyanov/ml-mipt/tree/master/amazon-howto \n",
    "    - Вам помогут tmux, CuDNN, ssh tunnel, nvidia-smi, ... \n",
    "    - Wish you get fun :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "depth = 3\n",
    "depth_out = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_cnn(input_var=None, n=5):\n",
    "    def residual_block(l, increase_dim=False, projection=False):\n",
    "        input_num_filters = l.output_shape[1]\n",
    "        if increase_dim:\n",
    "            first_stride = (2,2)\n",
    "            out_num_filters = input_num_filters*2\n",
    "        else:\n",
    "            first_stride = (1,1)\n",
    "            out_num_filters = input_num_filters\n",
    "        stack_1 = batch_norm(ConvLayer(l, num_filters=out_num_filters, filter_size=(3,3), stride=first_stride, nonlinearity=rectify, pad='same', W=lasagne.init.HeNormal(gain='relu'), flip_filters=False))\n",
    "        stack_2 = batch_norm(ConvLayer(stack_1, num_filters=out_num_filters, filter_size=(3,3), stride=(1,1), nonlinearity=None, pad='same', W=lasagne.init.HeNormal(gain='relu'), flip_filters=False))\n",
    "        if increase_dim:\n",
    "            if projection:\n",
    "                projection = batch_norm(ConvLayer(l, num_filters=out_num_filters, filter_size=(1,1), stride=(2,2), nonlinearity=None, pad='same', b=None, flip_filters=False))\n",
    "                block = NonlinearityLayer(ElemwiseSumLayer([stack_2, projection]),nonlinearity=rectify)\n",
    "            else:\n",
    "                identity = ExpressionLayer(l, lambda X: X[:, :, ::2, ::2], lambda s: (s[0], s[1], s[2]//2, s[3]//2))\n",
    "                padding = PadLayer(identity, [out_num_filters//4,0,0], batch_ndim=1)\n",
    "                block = NonlinearityLayer(ElemwiseSumLayer([stack_2, padding]),nonlinearity=rectify)\n",
    "        else:\n",
    "            block = NonlinearityLayer(ElemwiseSumLayer([stack_2, l]),nonlinearity=rectify)\n",
    "        return block\n",
    "    l_in = InputLayer(shape=(None, 3, 32, 32), input_var=input_var)\n",
    "    l = batch_norm(ConvLayer(l_in, num_filters=32, filter_size=(3,3), stride=(1,1), nonlinearity=rectify, pad='same', W=lasagne.init.HeNormal(gain='relu'), flip_filters=False))\n",
    "    for _ in range(n):\n",
    "        l = residual_block(l)\n",
    "    l = residual_block(l, increase_dim=True)\n",
    "    for _ in range(1,n):\n",
    "        l = residual_block(l)\n",
    "    l = residual_block(l, increase_dim=True)\n",
    "    for _ in range(1,n):\n",
    "        l = residual_block(l)\n",
    "    l = GlobalPoolLayer(l)\n",
    "    l = lasagne.layers.DenseLayer(l, num_units=64, W=lasagne.init.HeNormal(), nonlinearity=lasagne.nonlinearities.rectify)\n",
    "    network = DenseLayer(\n",
    "            l, num_units=10,\n",
    "            W=lasagne.init.HeNormal(),\n",
    "            nonlinearity=softmax)\n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# net = lasagne.layers.InputLayer(shape=(None, 3, 32, 32), input_var=input_X)\n",
    "\n",
    "# for i in range(depth):\n",
    "#     net = lasagne.layers.ConvLayer(net, 128 // (i+1), 3, pad='full', nonlinearity=lasagne.nonlinearities.rectify)\n",
    "#     net = batch_norm(net)\n",
    "#     net = MaxPool2DLayer(net, pool_size=(2, 2),stride=2,name=\"pool\")\n",
    "# for i in range(depth_out):\n",
    "#     net = lasagne.layers.DenseLayer(net, num_units=512 // (i + 1), nonlinearity=lasagne.nonlinearities.rectify)\n",
    "# net = lasagne.layers.DenseLayer(net,num_units = 10, nonlinearity=softmax)\n",
    "net = build_cnn(input_X, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W, beta, gamma, W, beta, gamma, W, beta, gamma, W, beta, gamma, W, beta, gamma, W, beta, gamma, W, beta, gamma, W, beta, gamma, W, beta, gamma, W, beta, gamma, W, beta, gamma, W, beta, gamma, W, beta, gamma, W, beta, gamma, W, beta, gamma, W, beta, gamma, W, beta, gamma, W, beta, gamma, W, beta, gamma, W, beta, gamma, W, beta, gamma, W, beta, gamma, W, beta, gamma, W, beta, gamma, W, beta, gamma, W, beta, gamma, W, beta, gamma, W, beta, gamma, W, beta, gamma, W, beta, gamma, W, beta, gamma, W, b, W, b]\n"
     ]
    }
   ],
   "source": [
    "y_predicted = lasagne.layers.get_output(net)\n",
    "all_weights = lasagne.layers.get_all_params(net, trainable=True)\n",
    "print all_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss = lasagne.objectives.categorical_crossentropy(y_predicted, target_y).mean()#<функция потерь>\n",
    "all_layers = lasagne.layers.get_all_layers(net)\n",
    "l2_penalty = lasagne.regularization.regularize_layer_params(all_layers, lasagne.regularization.l2) * 0.0001\n",
    "loss = loss + l2_penalty\n",
    "accuracy = lasagne.objectives.categorical_accuracy(y_predicted, target_y).mean()#<вычисление точност>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.setrecursionlimit(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sh_lr = theano.shared(lasagne.utils.floatX(0.1))\n",
    "updates = lasagne.updates.momentum(\n",
    "                loss, all_weights, learning_rate=sh_lr, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_fun = theano.function([input_X,target_y],[loss, accuracy], updates=updates)\n",
    "accuracy_fun = theano.function([input_X,target_y],accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вот и всё, пошли её учить"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
    "    assert len(inputs) == len(targets)\n",
    "    if shuffle:\n",
    "        indices = np.arange(len(inputs))\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, len(inputs) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt], targets[excerpt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Процесс обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 60 took 193.731s\n",
      "Epoch 1 of 60 took 198.118s\n",
      "  training loss (in-iteration):\t\t0.340322\n",
      "  train accuracy:\t\t97.59 %\n",
      "  validation accuracy:\t\t92.32 %\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-3b50876d3b60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mtrain_err_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc_batch\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtrain_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mtrain_err\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtrain_err_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mtrain_acc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtrain_acc_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vlad/PYENV/py2.7/local/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "num_epochs = 60 #количество проходов по данным\n",
    "\n",
    "batch_size = 256 #размер мини-батча\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # In each epoch, we do a full pass over the training data:\n",
    "    train_err = 0\n",
    "    train_acc = 0\n",
    "    train_batches = 0\n",
    "    start_time = time.time()\n",
    "    for batch in iterate_minibatches(X_train.astype(np.float32),\n",
    "                                     y_train.astype(np.float32),batch_size, shuffle=True):\n",
    "        inputs, targets = batch\n",
    "        inputs = inputs.astype(np.float32)\n",
    "        targets = targets.astype(np.int32)\n",
    "        train_err_batch, train_acc_batch= train_fun(inputs, targets)\n",
    "        train_err += train_err_batch\n",
    "        train_acc += train_acc_batch\n",
    "        train_batches += 1\n",
    "\n",
    "    # And a full pass over the validation data:\n",
    "    val_acc = 0\n",
    "    val_batches = 0\n",
    "    print(\"Epoch {} of {} took {:.3f}s\".format(epoch + 1, num_epochs, time.time() - start_time))\n",
    "    if (epoch + 1) % 1 == 0:\n",
    "        for batch in iterate_minibatches(X_test, y_test, batch_size):\n",
    "            inputs, targets = batch\n",
    "            targets = targets.astype(np.int32)\n",
    "            val_acc += accuracy_fun(inputs, targets)\n",
    "            val_batches += 1\n",
    "\n",
    "        # Then we print the results for this epoch:\n",
    "        print(\"Epoch {} of {} took {:.3f}s\".format(epoch + 1, num_epochs, time.time() - start_time))\n",
    "        print(\"  training loss (in-iteration):\\t\\t{:.6f}\".format(train_err / train_batches))\n",
    "        print(\"  train accuracy:\\t\\t{:.2f} %\".format(train_acc / train_batches * 100))\n",
    "        print(\"  validation accuracy:\\t\\t{:.2f} %\".format(val_acc / val_batches * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final results:\n",
      "  test accuracy:\t\t92.76 %\n",
      "Achievement unlocked: колдун 80 уровня\n"
     ]
    }
   ],
   "source": [
    "test_acc = 0\n",
    "test_batches = 0\n",
    "for batch in iterate_minibatches(X_test, y_test, 500):\n",
    "    inputs, targets = batch\n",
    "    targets = targets.astype(np.int32)\n",
    "    acc = accuracy_fun(inputs, targets)\n",
    "    test_acc += acc\n",
    "    test_batches += 1\n",
    "print(\"Final results:\")\n",
    "print(\"  test accuracy:\\t\\t{:.2f} %\".format(\n",
    "    test_acc / test_batches * 100))\n",
    "\n",
    "if test_acc / test_batches * 100 > 80:\n",
    "    print \"Achievement unlocked: колдун 80 уровня\"\n",
    "else:\n",
    "    print \"Нужно больше магии!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Заполните форму\n",
    "\n",
    "https://goo.gl/forms/EeadABISlVmdJqgr2 "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "py2.7",
   "language": "python",
   "name": "py2.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
